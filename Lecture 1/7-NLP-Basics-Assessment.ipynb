{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assessment we'll be using the short story [_An Occurrence at Owl Creek Bridge_](https://en.wikipedia.org/wiki/An_Occurrence_at_Owl_Creek_Bridge) by Ambrose Bierce (1890). <br>The story is in the public domain; the text file was obtained from [Project Gutenberg](https://www.gutenberg.org/ebooks/375.txt.utf-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create a Doc object from the file `owlcreek.txt`**<br>\n",
    "> HINT: Use `with open('../TextFiles/owlcreek.txt') as f:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "with open('../TextFiles/owlcreek.txt', \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "doc = nlp(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AN OCCURRENCE AT OWL CREEK BRIDGE\n",
       "\n",
       "by Ambrose Bierce\n",
       "\n",
       "I\n",
       "\n",
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to verify it worked:\n",
    "\n",
    "doc[:36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many tokens are contained in the file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 4835\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens:\", len(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How many sentences are contained in the file?**<br>HINT: You'll want to build a list first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 204\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = list(doc.sents)\n",
    "print(\"Number of sentences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Print the second sentence in the document**<br> HINT: Indexing starts at zero, and the title counts as the first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The man's hands were behind\n",
       "his back, the wrists bound with a cord.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5. For each token in the sentence above, print its `text`, `POS` tag, `dep` tag and `lemma`<br>\n",
    "CHALLENGE: Have values line up in columns in the print output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\tDET\tdet\tthe\n",
      "man\tNOUN\tposs\tman\n",
      "'s\tPART\tcase\t's\n",
      "hands\tNOUN\tnsubj\thand\n",
      "were\tAUX\tROOT\tbe\n",
      "behind\tADP\tprep\tbehind\n",
      "\n",
      "\tSPACE\tdep\t\n",
      "\n",
      "his\tPRON\tposs\this\n",
      "back\tNOUN\tpobj\tback\n",
      ",\tPUNCT\tpunct\t,\n",
      "the\tDET\tdet\tthe\n",
      "wrists\tNOUN\tappos\twrist\n",
      "bound\tVERB\tacl\tbind\n",
      "with\tADP\tprep\twith\n",
      "a\tDET\tdet\ta\n",
      "cord\tNOUN\tpobj\tcord\n",
      ".\tPUNCT\tpunct\t.\n",
      " \tSPACE\tdep\t \n"
     ]
    }
   ],
   "source": [
    "# NORMAL SOLUTION:\n",
    "for token in sentences[1]:\n",
    "    print(f\"{token.text}\\t{token.pos_}\\t{token.dep_}\\t{token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text           POS            dep            lemma          \n",
      "The            DET            det            the            \n",
      "man            NOUN           poss           man            \n",
      "'s             PART           case           's             \n",
      "hands          NOUN           nsubj          hand           \n",
      "were           AUX            ROOT           be             \n",
      "behind         ADP            prep           behind         \n",
      "\n",
      "              SPACE          dep            \n",
      "              \n",
      "his            PRON           poss           his            \n",
      "back           NOUN           pobj           back           \n",
      ",              PUNCT          punct          ,              \n",
      "the            DET            det            the            \n",
      "wrists         NOUN           appos          wrist          \n",
      "bound          VERB           acl            bind           \n",
      "with           ADP            prep           with           \n",
      "a              DET            det            a              \n",
      "cord           NOUN           pobj           cord           \n",
      ".              PUNCT          punct          .              \n",
      "               SPACE          dep                           \n"
     ]
    }
   ],
   "source": [
    "# CHALLENGE SOLUTION:\n",
    "col_widths = [15, 15, 15, 15]\n",
    "\n",
    "print(\"{:<{}}{:<{}}{:<{}}{:<{}}\".format(\"Text\", col_widths[0], \"POS\", col_widths[1], \"dep\", col_widths[2], \"lemma\", col_widths[3]))\n",
    "\n",
    "for token in sentences[1]:\n",
    "    print(\"{:<{}}{:<{}}{:<{}}{:<{}}\".format(token.text, col_widths[0], token.pos_, col_widths[1], token.dep_, col_widths[2], token.lemma_, col_widths[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text**<br>\n",
    "HINT: You should include an `'IS_SPACE': True` pattern between the two words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library:\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pattern and add it to matcher:\n",
    "pattern = [{\"LOWER\": \"swimming\"}, {\"IS_SPACE\": True, \"OP\": \"*\"}, {\"LOWER\": \"vigorously\"}]\n",
    "matcher.add(\"Swimming\", [pattern])\n",
    "\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of matches called \"found_matches\" and print the list:\n",
    "found_matches = [(doc[start:end], start, end) for match_id, start, end in matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Print the text surrounding each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evade the bullets and, swimming\n",
      "vigorously, reach the bank,\n",
      "shoulder; he was now swimming\n",
      "vigorously with the current.  \n"
     ]
    }
   ],
   "source": [
    "for match in found_matches:\n",
    "    start = match[1] - 5  # 5 words before the match\n",
    "    end = match[2] + 5  # 5 words after the match\n",
    "    surrounding_text = doc[start:end]\n",
    "    print(surrounding_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTRA CREDIT:<br>Print the *sentence* that contains each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods and get away home.  \n",
      "The hunted man saw all this over his shoulder; he was now swimming\n",
      "vigorously with the current.  \n"
     ]
    }
   ],
   "source": [
    "for match in found_matches:\n",
    "    start = match[1]\n",
    "    end = match[2]\n",
    "    sentence = next(sent for sent in sentences if start <= sent.end and end >= sent.start)\n",
    "    print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
